{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakshi-Prajapati/ML_LABS/blob/main/ML_LAB12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "cM0J-GizLzCo",
        "outputId": "a5a2a154-25da-4411-b67d-17623eae04ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5, dtype=torch.uint8)\n",
            "num_epochs :  5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-a422f90fb3b2>:62: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  trainset=np.array(list(zip(X_train,y_train)))\n",
            "<ipython-input-36-a422f90fb3b2>:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  trainset=np.array(list(zip(X_train,y_train)))\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "  flatten_data=[]\n",
        "  for i in range(len(X_data)):\n",
        "    sample=X_data[i]\n",
        "    flatten_row=[]\n",
        "    for row in sample:\n",
        "      flatten_row+=list(row)\n",
        "      pass\n",
        "    pass\n",
        "    flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    pass\n",
        "  return np.array(flatten_data)\n",
        "  pass\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:100]\n",
        "y_train=y_train[0:100]\n",
        "\n",
        "# visualize one of the images in data set\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "# X_test=flatten(X_test)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "# X_test=scaler.transform(X_test)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "# X_test=torch.tensor(X_test)\n",
        "\n",
        "y_train=torch.tensor(y_train)\n",
        "# y_test=torch.tensor(y_test)\n",
        "\n",
        "print(y_train[0])\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 5000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"num_epochs : \",num_epochs)\n",
        "trainset=np.array(list(zip(X_train,y_train)))\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True)\n",
        "\n",
        "\n",
        "# dataiter = iter(trainloader)\n",
        "# for _ in range(len(X_train)-1):\n",
        "#   input,target=next(dataiter)\n",
        "#   print(target,input)\n",
        "#   pass\n",
        "# print(trainloader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from random import random\n",
        "\n",
        "def flatten(X_data):\n",
        "    flatten_data=[]\n",
        "    for i in range(len(X_data)):\n",
        "        sample=X_data[i]\n",
        "        flatten_row=[]\n",
        "        for row in sample:\n",
        "            flatten_row+=list(row)\n",
        "        flatten_data.append(np.array(flatten_row,dtype='float32'))\n",
        "    return np.array(flatten_data)\n",
        "\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1,hidden_dim2, output_dim):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, output_dim)\n",
        "        # self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        # self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        # out = self.fc3(out)\n",
        "        # out = self.sigmoid(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def predict(self,x):\n",
        "        \n",
        "        output=self.forward(x).tolist()\n",
        "        output_labels=[]\n",
        "        for elem in output : \n",
        "          lbl=elem.index(max(elem))\n",
        "          output_labels.append(lbl)\n",
        "        # print(output_labels)\n",
        "        output_labels=np.array(output_labels)\n",
        "        # print(\"label : \",lbl)\n",
        "        # print(output)\n",
        "        return output_labels\n",
        "        pass\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
        "\n",
        "X_train=X_train[0:100]\n",
        "X_test=X_test[0:100]\n",
        "y_train=y_train[0:100]\n",
        "y_test=y_test[0:100]\n",
        "\n",
        "# visualize one of the images in data set\n",
        "sample_image_mat=X_train[int(random()*len(X_train))]\n",
        "plt.imshow(sample_image_mat)\n",
        "plt.show()\n",
        "\n",
        "X_train=flatten(X_train)\n",
        "X_test=flatten(X_test)\n",
        "\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "\n",
        "X_train=torch.tensor(X_train)\n",
        "X_test=torch.tensor(X_test)\n",
        "y_train=torch.tensor(y_train)\n",
        "y_test=torch.tensor(y_test)\n",
        "\n",
        "print(y_train[0])\n",
        "\n",
        "batch_size = 10\n",
        "n_iters = 1000\n",
        "\n",
        "num_epochs = n_iters / (len(X_train) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "print(\"num_epochs : \",num_epochs)\n",
        "# trainset = [(X_train[i], y_train[i]) for i in range(len(X_train))]\n",
        "trainset=TensorDataset(X_train,y_train)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# dataiter = iter(trainloader)\n",
        "\n",
        "# while True:\n",
        "#   try:\n",
        "#     input, target = next(dataiter)\n",
        "#     print(target)\n",
        "#   except StopIteration:\n",
        "#     break\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim1 = 100\n",
        "hidden_dim2 = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = ANNModel(input_dim, hidden_dim1,hidden_dim2, output_dim)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# criterion=tf.keras.losses.CategoricalCrossentropy()\n",
        "criterion=nn.MSELoss()\n",
        "\n",
        "learning_rate = 0.2\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(trainloader):\n",
        "    inputs = Variable(images.view(-1, input_dim))\n",
        "    labels = Variable(labels)\n",
        "    optimizer.zero_grad()\n",
        "    outputs=model(inputs)\n",
        "    # outputs = torch.tensor(model(inputs),dtype=torch.float)\n",
        "    # labels = torch.tensor(labels,dtype=torch.float)\n",
        "    # print(outputs.shape,labels.shape)\n",
        "    # print(outputs,labels)\n",
        "    loss = criterion(outputs, labels)\n",
        "    # loss.backward()\n",
        "    optimizer.step()\n",
        "    # if (i+1) % 10 == 0:\n",
        "    #     print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "    #           % (epoch+1, num_epochs, i+1, len(trainset)//batch_size, loss.item()))\n",
        "    pass\n",
        "  pass\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "# print(model.forward())\n",
        "sample=torch.tensor(flatten([sample_image_mat]))\n",
        "print(model.predict(sample))\n",
        "y_pred=torch.tensor(model.predict(X_test))\n",
        "# print(y_pred,y_test)\n",
        "# print(accuracy_score(y_pred,y_test))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "DkoCm6FdbqoP",
        "outputId": "62d9d2d5-d630-46f4-cbaa-5bf5147b22fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5, dtype=torch.uint8)\n",
            "num_epochs :  100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "Accuracy: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ze4IcBtLMHS0"
      }
    }
  ]
}